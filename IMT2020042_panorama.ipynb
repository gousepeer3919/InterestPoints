{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and displaying the constituent images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = cv.imread(\"/home/gousepeer/Desktop/SEM6/VR/Assignment2/images/Image1.jpeg\")\n",
    "cv.imshow(\"Image 1\",image1)\n",
    "\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2 = cv.imread(\"/home/gousepeer/Desktop/SEM6/VR/Assignment2/images/Image2.jpeg\")\n",
    "cv.imshow(\"Image 2\",image2)\n",
    "\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to create a panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class makePanorama:\n",
    "    def __init__(self,image1,image2):\n",
    "        self.image1 = image1\n",
    "        self.image2 = image2\n",
    "        self.method = \"orb\"\n",
    "\n",
    "\n",
    "    def resizeImage(self,image,dimensions):\n",
    "       \n",
    "        resizedImage = cv.resize(image, dimensions)\n",
    "        return resizedImage\n",
    "\n",
    "\n",
    "    def grayScaleImage(self,image):\n",
    "        \n",
    "        grayImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        return grayImage\n",
    "\n",
    "\n",
    "    def preprocessImages(self,dimensions):\n",
    "       \n",
    "        self.image1 = self.resizeImage(self.image1,dimensions)\n",
    "        self.image2 = self.resizeImage(self.image2,dimensions)\n",
    "\n",
    "        self.grayImage1 = self.grayScaleImage(self.image1)\n",
    "        self.grayImage2 = self.grayScaleImage(self.image2)\n",
    "\n",
    "\n",
    "    def createDescriptor(self,nfeatures=2000):\n",
    "       \n",
    "        if self.method == 'sift':\n",
    "            descriptor = cv.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
    "        elif self.method == 'surf':\n",
    "            descriptor = cv.xfeatures2d.SURF_create(nfeatures=nfeatures)\n",
    "        elif self.method == 'brisk':\n",
    "            descriptor = cv.BRISK_create()\n",
    "        elif self.method == 'orb':\n",
    "            descriptor = cv.ORB_create(nfeatures=2000)\n",
    "\n",
    "        self.descriptor = descriptor\n",
    "        return self.descriptor\n",
    "\n",
    "\n",
    "    def getKeypointDescriptors(self,image):\n",
    "       \n",
    "        self.createDescriptor()\n",
    "        (keypoints, descriptors) = self.descriptor.detectAndCompute(image, None)        \n",
    "        return (keypoints, descriptors)  \n",
    "\n",
    "\n",
    "    def drawKeypoints(self,image,keypoints,desc):\n",
    "       \n",
    "        cv.imshow(desc,cv.drawKeypoints(image, keypoints, None, (245, 228, 52)))\n",
    "        cv.waitKey(1)      \n",
    "\n",
    "\n",
    "    def createMatcher(self,crossCheck):        \n",
    "       \n",
    "        if self.method == 'sift' or self.method == 'surf':\n",
    "            self.bf = cv.BFMatcher(cv.NORM_L2, crossCheck=crossCheck)\n",
    "        elif self.method == 'orb' or self.method == 'brisk':\n",
    "            self.bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=crossCheck)\n",
    "        return self.bf\n",
    "\n",
    "\n",
    "    def ratioTest(self,rawMatches,ratio):\n",
    "      \n",
    "        matches = []\n",
    "        for m,n in rawMatches:\n",
    "            if m.distance < n.distance * ratio:\n",
    "                matches.append(m)\n",
    "        return matches        \n",
    "\n",
    "    \n",
    "    def matchPointsKNN(self,img1Features,img2Features,ratio):\n",
    "      \n",
    "        self.createMatcher(False)\n",
    "        rawMatches = self.bf.knnMatch(img1Features,img2Features,2)\n",
    "        matches = self.ratioTest(rawMatches,ratio)\n",
    "        return matches\n",
    "\n",
    "\n",
    "    def drawMatchingStiches(self,keypointsImage1,keypointsImage2):\n",
    "       \n",
    "        img3 = cv.drawMatches(self.image1,keypointsImage1,self.image2,keypointsImage2,np.random.choice(matches,100), None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        cv.imshow(\"image3\",img3)\n",
    "        cv.waitKey(1)\n",
    "\n",
    "    \n",
    "    def stitchImages(self,img1, img2, H):\n",
    "       \n",
    "        rows1, cols1 = img1.shape[:2]\n",
    "        rows2, cols2 = img2.shape[:2]\n",
    "\n",
    "        PointsListImage1 = np.float32([[0,0], [0, rows1],[cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
    "        fovPoints = np.float32([[0,0], [0,rows2], [cols2,rows2], [cols2,0]]).reshape(-1,1,2)\n",
    "\n",
    "        PointsListImage2 = cv.perspectiveTransform(fovPoints, H)\n",
    "        PointsList = np.concatenate((PointsListImage1,PointsListImage2), axis=0)\n",
    "\n",
    "        [xmin, ymin] = np.int32(PointsList.min(axis=0).ravel() - 0.5)\n",
    "        [xmax, ymax] = np.int32(PointsList.max(axis=0).ravel() + 0.5)\n",
    "        \n",
    "        transformDistance = [-xmin,-ymin]\n",
    "        \n",
    "        HTranslation = np.array([[1, 0, transformDistance[0]], [0, 1, transformDistance[1]], [0, 0, 1]])\n",
    "\n",
    "        outputImage = cv.warpPerspective(img2, HTranslation.dot(H), (xmax - xmin, ymax - ymin))\n",
    "        outputImage[transformDistance[1]:rows1 + transformDistance[1], transformDistance[0]:cols1 + transformDistance[0]] = img1\n",
    "\n",
    "        return outputImage\n",
    "\n",
    "\n",
    "    def getHomographyMatrix(self,matchCount,keypointsImage1,keypointsImage2):\n",
    "      \n",
    "        if len(matches) > matchCount:\n",
    "            Image1Points = np.float32([ keypointsImage1[m.queryIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "            Image2Points = np.float32([ keypointsImage2[m.trainIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "\n",
    "            matrix,mask = cv.findHomography(Image1Points, Image2Points, cv.RANSAC,5.0)\n",
    "            self.result = self.stitchImages(self.image2,self.image1, matrix)\n",
    "            return matrix,mask,self.result \n",
    "\n",
    "\n",
    "    def getImage1(self):\n",
    "     \n",
    "        return self.image1\n",
    "\n",
    "    def getImage2(self):\n",
    "        \n",
    "        return self.image2\n",
    "\n",
    "    def setMethod(self,method):\n",
    "        \n",
    "        self.method = method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "panorama = makePanorama(image1,image2)\n",
    "panorama.preprocessImages((600,500))\n",
    "panorama.setMethod(\"orb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = panorama.getImage1()\n",
    "image2 = panorama.getImage2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow(\"Preprocessed Image 1\",image1)\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow(\"Preprocessed Image 2\",image2)\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Distinctive Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(keypointsImage1,descriptorsImage1) = panorama.getKeypointDescriptors(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(keypointsImage2,descriptorsImage2) = panorama.getKeypointDescriptors(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "panorama.drawKeypoints(panorama.image1,keypointsImage1,\"Keypoints Image 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "panorama.drawKeypoints(panorama.image2,keypointsImage2,\"Keypoints Image 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Matcher Stiches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = panorama.matchPointsKNN(descriptorsImage1, descriptorsImage2, ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "panorama.drawMatchingStiches(keypointsImage1,keypointsImage2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix,mask,result = panorama.getHomographyMatrix(10,keypointsImage1,keypointsImage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv.imshow(\"result\",result)\n",
    "cv.waitKey(1)\n",
    "\n",
    "cv.imwrite(\"result.jpg\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
